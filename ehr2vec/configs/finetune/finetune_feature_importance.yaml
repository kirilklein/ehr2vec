env: local

paths:
  model_path: "../outputs/pretraining/test/finetune_TEST_OUTCOME_censored_24_hours_pre_TEST_CENSOR_followup_start_at_index_date_test"
  # data_dir: "../outputs/pretraining/test/finetune_TEST_OUTCOME_censored_24_hours_pre_year2015_month1_day1_followup_start_at_index_date_test" 
  run_name: "perturb_fi"

metrics:
  roc_auc:
    _target_: ehr2vec.evaluation.metrics.ROC_AUC
  pr_auc:
    _target_: ehr2vec.evaluation.metrics.PR_AUC
model:
  lambda: .001
  scale_with_frequency: true
data:
  min_len: 1
  # preprocess: True

trainer_args:
  sampler: true
  sample_weight_function:
    _target_: ehr2vec.evaluation.utils.inverse_sqrt # function to calculate sample weights
  sample_weight_multiplier: 1 # adjust the sampling weight of the positive class (1 is balanced)
  pos_weight: null # weight for positive class in the loss
  batch_size: 8
  val_batch_size: 16
  effective_batch_size: 16
  epochs: 2
  info: true
  gradient_clip: 
    clip_value: 1.0
  mixed_precision: false
  shuffle: true
  checkpoint_frequency: 1
  early_stopping: 20
  stopping_criterion: roc_auc

scheduler:
  _target_: transformers.get_constant_schedule_with_warmup
  num_warmup_epochs: 5

optimizer:
  lr: 5e-3
  eps: 1e-6